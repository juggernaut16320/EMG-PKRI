| 学  位  论  文  研  究  内  容 | 学位论文的研究目标、研究内容及拟解决的关键性问题（可续页）   **一、研究目标**  本课题旨在构建一种面向边缘设备的高可靠中文敏感文本识别框架，解决在语义模糊、表达隐晦、文本变形等复杂场景中，大模型分类系统存在的高置信错误与外部知识不稳定干扰等问题。为此，本文提出融合不确定性建模与知识可靠性控制的双通路机制，包括：  1. 基于证据不确定性的单调融合门控机制（EvidenceDriven  Monotone Gating, EMG），以建模“越不确定越依赖知识”的可验证策略；  2. 概率化知识可靠性建模接口（Probabilistic  Knowledge Reliability Interface, PKRI），将外部词典/别名等启发性资源转化为可校准的知识后验概率。  本研究目标在于，在边缘资源受限的环境下，构建一个高解释性、高校准度、推理一致的中文敏感文本识别系统，兼顾语义消歧能力与端侧部署可行性。      **二、研究内容**  本课题主要研究内容包括以下三个方面：   （1）中文敏感文本中的不确定性建模与任务切片  在中文敏感内容识别中，表达形式往往存在高度变异性（如谐音替换、形似字、拼音编码、语境双关等），使得模型产生高置信低正确率的判断错误。为刻画此类“危险决策”区域，本文将基于证据深度学习(（evidential deep learning, EDL） 构建模型输出的Dirichlet 参数表示，定义证据不确定性度量u，并将预测样本按u值划分为若干区间，用于后续门控机制与风险分析。      （2）基于不确定性的单调融合门控（EMG）  为动态调整模型与外部知识的融合程度，本文设计一种证据驱动的单调门控函数                                                                       。该函数通过在各不确定度区间内最小化条件风险（negative loglikelihood）来学习最优融合权重，并采用保序回归（isotonic  regression, PAV）进行单调约束，使其满     。该门控机制保证：    在高不确定区，融合引入的期望风险不升     ；   推理过程可导出为查表/两参数函数，满足边缘部署一致性要求；  融合输出     在全局满足风险控制与校准改进目标。      （3）可解释的知识可靠性接口（PKRI）设计与校准融合  外部知识来源（如行业敏感词表、别名映射、词向量匹配）在中文敏感文本场景中往往存在强启发性但低一致性的问题。为防止其对主模型形成不稳定干扰，本文提出基于特征提取的知识可信度建模模块（PKRI），主要包括：  对每条命中知识边提取特征（如共现频次、上下文一致性、OOV比等）；  使用逻辑回归+温度/Platt/保序校准生成可信度     ；  得到校准后的知识后验概率分布     ，可与主模型后验        在同一空间融合。  该模块有助于在高噪声或语义歧义区域控制知识引入风险，提升融合系统在高u区域的稳健性和解释性。      **三、拟解决的关键性问题**  为实现上述研究目标，论文拟聚焦以下几个关键性科学与工程问题：  1. 如何构建“越不确定越依赖知识”的可验证融合机制？  面对边缘端中文文本的模糊表达，模型应如何基于证据不确定性自适应调整知识引入强度？  如何确保该调控机制满足结构性单调性与训练–推理一致性，并能导出为轻量推理表结构？     2. 如何对外部知识的质量和可信度进行有效建模与校准？    外部知识来源往往存在冗余、歧义或噪声，如何将其从黑盒规则转化为概率化后验，支持风险控制式融合？    如何设计可解释的知识边特征组合，并通过轻量模型（如逻辑回归）完成有效拟合与区间收缩校准？     3. 如何在边缘设备上实现高可靠、低延迟的敏感文本识别？  面向中文敏感文本识别等具备实时性与部署约束的场景，如何设计推理时延极低、推理路径可控的融合系统？  融合函数       与知识后验       是否可导出为查表结构/闭式函数，实现端侧一致性执行？  在无大规模检索系统支持下，如何依托本地  alias 映射或轻量级表结构，完成复杂语义的部分知识显式引入（如谐音、错别字）？     4. 如何以统一指标体系验证融合系统的可靠性提升？    是否能构造合理的验证基准，支持对“误判但高置信”（错误自信率）的显著降低验证？    能否在高不确定性切片中展现 ECE 下降、F1 提升的可复验指标效果，支撑理论假设与门控设计？ |
| ------------------------------ | ------------------------------------------------------------ |
|                                |                                                              |



一、学位论文研究依据

  学位论文的选题依据和研究意义，国内外研究现状和发展态势；选题在理论研究或实际应用方面的意义和价值；主要参考文献，以及已有的工作积累和研究成果。（2000字）     **一、** **选题依据与研究意义**  随着大型语言模型（LLM）在自然语言处理任务中的广泛应用，研究者在语言理解、生成、问答和推理等方面取得了显著突破。然而，实际应用中，中文敏感文本的识别仍是一项具备挑战性和行业价值的任务。该任务不仅要求模型具备高准确率，还需对语义隐喻、讽刺修辞、拼写错变形、谐音变体等现象具备鲁棒判断能力。尤其在政策、金融、医疗等敏感场景下，误报或漏报的代价高昂，因此如何构建高可信、低误信的融合模型成为关键问题。  与此同时，随着物联网终端、移动设备、专用审查芯片等边缘计算资源的快速发展，将敏感文本识别能力迁移至边缘设备成为刚需。这不仅涉及推理时延、功耗等工程问题，也对模型结构的可解释性与可控性提出挑战。尤其是在缺乏云端算力与大规模外部知识支持的情况下，如何在本地构建一套置信度可控、知识融合可证的文本分类机制，具备突出的理论与实际意义。  基于上述背景，本研究提出一种融合结构性门控与知识后验建模的端侧文本判别系统，核心由以下两个机制构成：  (1)证据驱动单调门控机制（EMG）：通过将模型输出的不确定性作为门控变量，引导知识融合过程满足“越不确定，越依赖知识”的单调约束。门控函数由保序回归学习，具备结构解释性与融合可验证性。  (2)知识可靠性后验接口（PKRI）：对知识命中边构建多维特征（上下文一致性、共现强度、OOV比例等），经逻辑回归与温度校准转化为可融合后验       ，实现与模型后验       的同空间比较与融合。  两机制结合形成一套端侧可部署、结构化可解释、风险可控的文本分类架构，补齐当前领域在“融合机制可靠性”与“边缘部署适配性”方面的空白。      **二、国内外研究现状与发展态势**   2.1 不确定性建模与输出校准  近年来，模型置信度建模已逐渐成为主流趋势。Gal 与  Ghahramani提出将 Dropout 看作贝叶斯推理的近似方法[1]，为模型提供自然的不确定性表达。Guo 等工作引入温度缩放机制对  Softmax 结果进行后处理校准[2]，进一步提升模型置信的一致性。而保序回归（PAV）因其对单调性建模的支持[3]，广泛应用于医学预测、风控等对置信要求高的场景中。  然而现有方法大多关注分类输出自身的校准，缺乏利用不确定性信号进一步引导模型融合或拒识机制的研究。同时，缺乏将此类机制应用于中文多义文本或边缘环境下的实践验证。因此本课题提出将不确定性信号转化为结构门控，是这一方向的实质推进。      2.2 外部知识融合与可信建模  知识增强方法（KENLP）已在实体识别、关系抽取等任务中展现强大潜力。ERNIE[6]、KnowBERT[7]等工作通过显式引入实体信息，改善语言理解精度。但此类方法依赖大规模预训练阶段，难以直接迁移至小模型或边缘环境。  检索增强（RAG）模型近年来快速发展，将语义相近文段检索作为编码输入扩展，提升推理质量。然而主流 RAG 机制多为正向检索  + 段落拼接 + 编码共享结构，缺乏对检索片段可靠性的动态建模。Dhol提出根据不确定性动态决定是否调用检索[8]，而 Kim强调检索项自身的置信校准必要性[9]。这一系列工作表明：可信度驱动的融合策略才是面向落地的关键课题。  本课题所提出的 PKRI 接口，是当前研究中少有从知识融合过程本身出发建立结构校准机制的方案，为后验建模提供更可解释与调节的控制信号。      2.3 边缘部署趋势与量化压缩发展  从部署角度看，轻量化模型已成为 LLM 实际落地的关键突破口。MiniLM  系列提出基于注意力蒸馏的子模型压缩框架[4][5]，在小模型中继承主干语义能力。EdgeQAT[11]、AgileQuant等进一步结合权重、激活量化、对称剪枝等手段[10]，使模型适配嵌入式平台运行。  值得注意的是，Zhang提出利用  Hessian 信息进行层级量化策略[12]，在不显著损害精度前提下实现量级压缩，是边缘部署路径中的重要探索。  总体而言，现有部署方案集中在计算层与架构压缩层，对模型融合策略与推理路径的可靠性未建立结构化保障机制。而在国产手机、国产 NPU、政府审核终端等场景下，中文敏感文本审核的边缘部署需求日益强烈，本课题目标机制具有明显的现实需求与技术空白对接意义。      **三、选题的理论意义与实际应用价值**   3.1 理论意义  本课题在 LLM 结构优化方向提出以下理论贡献：  （1）提出结构性门控机制（EMG）作为融合函数框架，通过保序学习构建“置信→融合强度”映射关系，具备理论一致性与可验证性；  （2）构建知识可靠性校准模型（PKRI），以回归方式将多元启发式特征转化为后验分布，使知识在概率空间中具备统一融合语义；  （3）提出一种置信度双通道融合结构，将内部模型置信与外部知识置信联合建模，首次从结构层面对融合逻辑的可信性做约束；  （4）对中文文本判别中的“否定/反讽/谐音”等特征进行显式建模，提升中文 NLP 研究体系的完备性。  这些机制不仅能用于敏感文本场景，也为风控、医疗报告筛查等任务提供理论支撑。      3.2 应用价值  应用方面，本课题直接对接以下落地需求：  （1）内容安全审查：移动端、专网终端等设备需实时处理大量文本，具备低延迟、高保密需求，当前方案缺乏稳定融合机制。  （2）金融/舆情风控：对模型预测误报容忍度极低，需要能解释、可拒识的模型结构，尤需中文语境支持。  （3）终端 LLM 微调部署：结合本课题提出机制与 LoRA、int8 方案，具备明确的轻量化部署路径与原型验证可能。  综上所述，选题兼具结构创新性与部署可行性，落地价值明确，具备良好的学术研究与工程应用前景。     **四、主要参考文献**  [1] Gal Y,  Ghahramani Z. Dropout as a Bayesian Approximation: Representing Model  Uncertainty in Deep Learning[C] (ICML). 2016.     [2] Guo C,  Pleiss G, Sun Y, et al. On Calibration of Modern Neural Networks[C](ICML).  2017.     [3]  Niculescu-Mizil A, Caruana R. Predicting Good Probabilities with Supervised  Learning[C] (KDD). 2005.     [4] Wang W, Wei  F, Dong L, et al. MiniLM: Deep Self-Attention Distillation for Task-Agnostic  Compression of Pre-Trained Transformers[C] (NeurIPS). 2020.     [5] Wang W, Bao  H, Huang S, et al. MiniLMv2: Multi-Head Self-Attention Relation Distillation  for Compressing Pretrained Transformers[J]. In Proceedings of ACL, 2021.     [6] Sun Y, Wang  S, Li Y, et al. ERNIE: Enhanced Language Representation with Informative  Entities[C] (IJCAI). 2019.     [7] Peters M E,  Neumann M, Logan IV R, et al. Knowledge Enhanced Contextual Word  Representations[C] (EMNLP). 2019.     [8] Dhole K,  Risch J, et al. To Retrieve or Not to Retrieve? Uncertainty Detection for  Dynamic RAG[J]     [9] Kim Y,  Nijkamp E, Ghosh S, et al. Reliability Across Parametric and External  Knowledge: Understanding Knowledge Handling in LLMs[J]     [10] Shen X,  Dong P, Kong Z, et al. Agile-Quant: Activation-Guided Quantization for LLMs  on the Edge[J].     [11] Shen X,  Kong Z, Yang C, et al. EdgeQAT: Entropy and Distribution Guided  Quantization-Aware Training[J]     [12] Zhang T, Li  N, Yuan X, et al. Efficient Edge LLMs Deployment via Hessian-Aware  Quantization[J].      [13] Han S, Mao  H, Dally W J. Deep Compression: Compressing Deep Neural Networks with  Pruning, Trained Quantization and Huffman Coding[J].     



二、学位论文研究计划及预期目标

  1.拟采取的主要理论、研究方法、技术路线和实施方案（可续页）   **一、拟采取的主要理论**  本课题以模型不确定性建模、单调结构函数学习以及知识后验校准与融合为核心理论基础，结合边缘部署的需求对机制结构进行优化，形成完整的推理路径。主要涉及如下理论：  **(1)**    **基于证据不确定性的单调门控机制（****EMG****）**  模型在进行分类预测时，其输出的 Softmax 分布常被用作置信度估计。然而大量研究表明，Softmax 输出在面对模糊样本或  OOD 样本时容易过度自信，难以真实反映模型对样本的“认识不确定性”（epistemic uncertainty）。     为了构建基于不确定性的融合门控机制，课题采用基于分桶的条件风险最小化方法。记模型输出后验概率为 (     ，其最大值记为置信度     。将训练数据根据 不确定性度量u 分成B个区间（bucket）：                  对于每个区间 ( b )，计算融合策略下的经验风险：               其中       是融合权重，     是知识模块输出，      为交叉熵损失或  BCE。目标是在每个不确定度区间下求最优融合比例。  为防止过拟合与结构不可解释，本研究进一步引入保序约束（Isotonic Regression），在上述     最小化的基础上加入：            从而置信度越低，模型越依赖外部知识。这类单调约束可通过 PAV 算法求解，具备较低计算复杂度并可查表执行（inference lookup）。     **(2)**  **知识边可信度建模与后验概率融合（****PKRI****）**  当前大多数知识增强方法将检索结果作为模型输入拼接后送入编码器，忽略了知识本身的“来源可信性”差异。为此，课题提出一种知识后验建模机制，即对每一条命中知识边，计算其可信度     ，并将其用于构建知识后验     ，与模型后验进行融合。  知识边特征构成为向量     ，包括：共现强度（PMI），局部上下文一致性（embedding  cosine）， OOV  率（是否存在未登录词），源图谱置信（词典来源或别名层级）  采用逻辑回归对其建模：     [         随后使用温度缩放进行概率校准：            其中温度 ( T > 0 ) 为超参数或通过验证集学习得来。此外，为避免高置信但低准确的过拟合风险，还使用置信区间收缩法（Beta Calibration 或 Isotonic Shrinkage）进一步将       限制在模型校准区域内。     最后，构造带权重融合的知识后验：               其中       是第k条知识边预测类别，      为其可信度。该分布与模型后验       相同维度，可直接用于融合或门控输入。     （**3****）融合框架与结构一致性设计**  整体预测可表示为结构融合：         其中     为从模型置信度 ( u ) 映射得到的融合权重函数，满足单调性。此融合具有以下性质：  结构可解释性：融合权重函数α(u)具有直观解释力，可明确指示模型何时信任自身预测，何时转而依赖外部知识；  训练推理一致性：门控函数为查表/插值，可部署至边缘设备中执行；  组合风险下界控制：融合后风险在分桶层次具备可验证下降。  此外，本研究也考虑在训练阶段引入辅助损失（如知识校准 KL Loss），确保模型学习使用可靠知识而非无差别拼接。     **二、研究方法**  本课题采用理论建模与系统工程并重的研究方法，围绕边缘端中文敏感文本识别中的融合机制展开，关键包括以下方法路径：  （1）模型不确定性引导的融合策略优化  以  Qwen-1.7B 模型作为主干语言理解框架，抽取其输出概率中的最大类置信度作为代理不确定度指标      ，结合训练样本的条件风险，设计单调融合函数     ，用于自适应调节模型输出与知识后验之间的权重关系  。  （2）轻量知识后验建模与校准  采用启发式规则库（如敏感词 alias 表、谐音映射、同义词图谱）构建知识图，借助知识边的特征表示（PMI、上下文一致性等）训练逻辑回归预测边可信度，再经 Platt/温度缩放进行概率化，构造校准后验 ( q(c|z) )。     3）结构可部署的融合输出与性能校验  最终决策结果通过结构化融合公式：         融合结构支持查表实现、闭式计算以及边缘硬件推理路径规划，适用于时延敏感部署场景。     **三、技术路线**  技术路径上，课题系统划分为训练阶段（包含离线校准）、模型集成与轻量部署三大阶段：  （1）模型微调阶段  主模型：选用  Qwen-1.7B 作为基础语言模型。  微调方法：若实验资源充足，将采用参数高效微调方式（LoRA）对部分 Transformer 模块调节适应敏感文本语料；LoRA 插件位置选择包括  attention query/key/value 层，设置 rank=8~16，保证推理时开销可控；若资源受限则采用 Prompt Tuning 或 Adapter  方法作为替代，保留 Qwen 主干结构。  训练数据：构建中文敏感样本子集，涵盖形似、谐音、隐喻、否定类文本；每条数据构建双输出目标：主模型分类标签 + 外部知识边特征集合。     （2）证据门控与知识接口训练  不确定度计算：统计  Softmax 输出最高概率；  分桶划分：设定  B=10 个置信度区间；  门控权重训练：每个区间训练最优，采用 PAV 算法做保序回归；  知识特征提取与校准：提取边特征向量 ( f )，包括上下文余弦相似度、词频共现、alias 匹配深度等；使用逻辑回归建模可信度；使用温度缩放（或 Beta 校准）对其输出进行归一化，形成可信概率。     （3）融合推理实现与边缘部署优化  推理路径精简：将     拟合为查表函数（或 1D 插值表达）；构建知识后验  ( q(c|z) ) 的稀疏表达（Top-k 或逻辑门控）；构建最终融合输出。  部署实现：模型裁剪/量化（支持 int8）；转换至边缘推理引擎（如 NCNN / ONNX / TensorRT）；代码上构建融合策略的  C++ 推理模块或 Python 解释模块。     **四、实施方案与阶段目标**  阶段一：敏感数据构建、Qwen1.7B适配、知识图资源整理，输出实验语料和知识图结构。        阶段二：主模型微调（LoRA/Prompt）、门控函数学习 ，输出微调模型和     门控表。  阶段三：知识接口特征设计、可信度校准训练，输出PKRI模块和q(c|z)生成代码。  阶段四：融合系统集成与边缘推理测试，输出推理demo和延迟/风险评估报告。    |         