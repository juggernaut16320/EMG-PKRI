# qâ‚€ æ”¹è¿›æ–¹æ¡ˆ

**é—®é¢˜**ï¼šqâ‚€ å¹³å‡æ•æ„Ÿæ¦‚ç‡ 0.82 è¿‡é«˜ï¼Œå¯èƒ½å¯¼è‡´ Precision ä½ï¼Œåœ¨ EMG èåˆæ—¶å¼•å…¥å™ªå£°

---

## ğŸ“Š ç¬¬ä¸€æ­¥ï¼šè¯„ä¼° qâ‚€ è´¨é‡

### åˆ›å»ºè¯„ä¼°è„šæœ¬

é¦–å…ˆéœ€è¦è¯„ä¼°å½“å‰ qâ‚€ çš„è´¨é‡ï¼Œç¡®å®šé—®é¢˜æ‰€åœ¨ã€‚

**åˆ›å»ºè„šæœ¬ï¼š`scripts/eval_q0.py`**

```python
"""
è¯„ä¼° qâ‚€ çš„è´¨é‡ï¼ˆPrecision/Recall/F1/Accuracyï¼‰
"""
import json
import argparse
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix
import pandas as pd

def load_q0_and_labels(q0_file: str, baseline_file: str = None):
    """åŠ è½½ qâ‚€ å’ŒçœŸå®æ ‡ç­¾"""
    q0_dict = {}
    true_labels = []
    q0_labels = []
    
    # ä» q0_file åŠ è½½ qâ‚€
    with open(q0_file, 'r', encoding='utf-8') as f:
        for line in f:
            item = json.loads(line)
            q0 = item['q0']
            q0_dict[item['id']] = q0
            # qâ‚€ é¢„æµ‹ï¼šå¦‚æœ p_sensitive > 0.5ï¼Œé¢„æµ‹ä¸ºæ•æ„Ÿ
            q0_labels.append(1 if q0[1] > 0.5 else 0)
            if 'coarse_label' in item:
                true_labels.append(item['coarse_label'])
    
    # å¦‚æœ baseline_file æä¾›ï¼Œä»é‚£é‡Œè·å–çœŸå®æ ‡ç­¾
    if baseline_file:
        with open(baseline_file, 'r', encoding='utf-8') as f:
            for line in f:
                item = json.loads(line)
                if item['id'] in q0_dict:
                    true_labels.append(item['coarse_label'])
    
    return q0_dict, true_labels, q0_labels

def evaluate_q0(q0_file: str, baseline_file: str = None):
    """è¯„ä¼° qâ‚€ è´¨é‡"""
    q0_dict, true_labels, q0_labels = load_q0_and_labels(q0_file, baseline_file)
    
    if len(true_labels) == 0:
        print("âš ï¸ æ— æ³•åŠ è½½çœŸå®æ ‡ç­¾ï¼Œè¯·æä¾› baseline_file")
        return
    
    # è®¡ç®—æŒ‡æ ‡
    precision = precision_score(true_labels, q0_labels)
    recall = recall_score(true_labels, q0_labels)
    f1 = f1_score(true_labels, q0_labels)
    accuracy = accuracy_score(true_labels, q0_labels)
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(true_labels, q0_labels)
    tn, fp, fn, tp = cm.ravel()
    
    print("=" * 60)
    print("qâ‚€ è´¨é‡è¯„ä¼°")
    print("=" * 60)
    print(f"Precision: {precision:.4f} ({precision*100:.2f}%)")
    print(f"Recall:    {recall:.4f} ({recall*100:.2f}%)")
    print(f"F1:        {f1:.4f} ({f1*100:.2f}%)")
    print(f"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)")
    print()
    print("æ··æ·†çŸ©é˜µ:")
    print(f"  TN (çœŸé˜´æ€§): {tn}")
    print(f"  FP (å‡é˜³æ€§): {fp}  â† è¯¯æŠ¥ï¼Œéœ€è¦å‡å°‘")
    print(f"  FN (å‡é˜´æ€§): {fn}")
    print(f"  TP (çœŸé˜³æ€§): {tp}")
    print()
    
    # åˆ†æå¹³å‡æ•æ„Ÿæ¦‚ç‡
    avg_p_sensitive = sum(q0[1] for q0 in q0_dict.values()) / len(q0_dict)
    print(f"å¹³å‡æ•æ„Ÿæ¦‚ç‡: {avg_p_sensitive:.4f}")
    
    # åˆ¤æ–­è´¨é‡
    if precision < 0.70:
        print("âš ï¸ qâ‚€ Precision < 0.70ï¼Œè´¨é‡è¾ƒå·®ï¼Œéœ€è¦æ”¹è¿›")
    elif precision < 0.75:
        print("âš ï¸ qâ‚€ Precision < 0.75ï¼Œè´¨é‡ä¸€èˆ¬ï¼Œå»ºè®®æ”¹è¿›")
    else:
        print("âœ… qâ‚€ Precision â‰¥ 0.75ï¼Œè´¨é‡è‰¯å¥½")
    
    return {
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'accuracy': accuracy,
        'avg_p_sensitive': avg_p_sensitive,
        'confusion_matrix': {'tn': int(tn), 'fp': int(fp), 'fn': int(fn), 'tp': int(tp)}
    }

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='è¯„ä¼° qâ‚€ è´¨é‡')
    parser.add_argument('--q0-file', type=str, required=True, help='qâ‚€ æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--baseline-file', type=str, default=None, help='Baseline æ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«çœŸå®æ ‡ç­¾ï¼‰')
    args = parser.parse_args()
    
    evaluate_q0(args.q0_file, args.baseline_file)
```

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
# è¯„ä¼° qâ‚€ è´¨é‡
python scripts/eval_q0.py \
    --q0-file data/q0_test.jsonl \
    --baseline-file output/test_with_uncertainty.jsonl
```

---

## ğŸ”§ æ”¹è¿›æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰

### æ–¹æ¡ˆ1ï¼šè°ƒæ•´ qâ‚€ è®¡ç®—å‚æ•°ï¼ˆæœ€ç®€å•ï¼Œç«‹å³ç”Ÿæ•ˆï¼‰

#### 1.1 é™ä½ max_sensitive_prob

**é—®é¢˜**ï¼šå½“å‰ `max_sensitive_prob = 0.95` å¤ªé«˜ï¼Œå¯¼è‡´åŒ¹é…åˆ°è¯è¡¨æ—¶æ¦‚ç‡è¿‡é«˜

**ä¿®æ”¹ `configs/config.yaml`**ï¼š
```yaml
q0:
  max_sensitive_prob: 0.75  # ä» 0.95 é™ä½åˆ° 0.75
  base_sensitive_prob: 0.1  # ä¿æŒä¸å˜
```

**æˆ–è€…é€šè¿‡å‘½ä»¤è¡Œå‚æ•°**ï¼š
```bash
python scripts/q0_builder.py \
    --max-sensitive-prob 0.75 \
    --datasets test
```

**é¢„æœŸæ•ˆæœ**ï¼š
- å¹³å‡æ•æ„Ÿæ¦‚ç‡ä» 0.82 é™ä½åˆ°çº¦ 0.65-0.70
- å‡å°‘è¯¯æŠ¥ï¼Œæé«˜ Precision

#### 1.2 æé«˜ min_matches_for_sensitive

**é—®é¢˜**ï¼šå½“å‰ `min_matches_for_sensitive = 1`ï¼Œåªè¦åŒ¹é…åˆ° 1 ä¸ªè¯å°±è§¦å‘æ•æ„Ÿ

**ä¿®æ”¹ `configs/config.yaml`**ï¼š
```yaml
q0:
  min_matches_for_sensitive: 2  # ä» 1 æé«˜åˆ° 2ï¼Œè¦æ±‚è‡³å°‘åŒ¹é… 2 ä¸ªè¯
```

**é¢„æœŸæ•ˆæœ**ï¼š
- å‡å°‘å•è¯è¯¯åŒ¹é…å¯¼è‡´çš„è¯¯æŠ¥
- æé«˜ Precisionï¼Œå¯èƒ½ç•¥å¾®é™ä½ Recall

#### 1.3 è°ƒæ•´ç±»åˆ«æƒé‡

**é—®é¢˜**ï¼šå½“å‰æƒé‡å¯èƒ½ä¸å¹³è¡¡ï¼Œå¯¼è‡´æŸäº›ç±»åˆ«è¿‡åº¦åŒ¹é…

**ä¿®æ”¹ `configs/config.yaml`**ï¼š
```yaml
q0:
  porn_weight: 1.0      # ä¿æŒä¸å˜
  politics_weight: 0.6  # ä» 0.8 é™ä½åˆ° 0.6ï¼ˆæ¶‰æ”¿è¯å¯èƒ½è¯¯æŠ¥å¤šï¼‰
  abuse_weight: 0.5    # ä» 0.6 é™ä½åˆ° 0.5ï¼ˆè¾±éª‚è¯å¯èƒ½è¯¯æŠ¥å¤šï¼‰
```

**é¢„æœŸæ•ˆæœ**ï¼š
- é™ä½è¯¯æŠ¥ç‡é«˜çš„ç±»åˆ«çš„æƒé‡
- æé«˜æ•´ä½“ Precision

#### 1.4 è°ƒæ•´æ¦‚ç‡è®¡ç®—ç¼©æ”¾å› å­

**é—®é¢˜**ï¼šå½“å‰ `tanh(match_score * 10)` çš„ç¼©æ”¾å› å­ 10 å¯èƒ½å¤ªå¤§

**ä¿®æ”¹ `scripts/q0_builder.py` ç¬¬ 278 è¡Œ**ï¼š
```python
# åŸä»£ç 
normalized_score = np.tanh(match_score * 10)  # ç¼©æ”¾å› å­ 10

# æ”¹ä¸ºæ›´ä¿å®ˆçš„ç¼©æ”¾
normalized_score = np.tanh(match_score * 5)  # é™ä½åˆ° 5ï¼Œä½¿æ¦‚ç‡å¢é•¿æ›´å¹³ç¼“
```

**é¢„æœŸæ•ˆæœ**ï¼š
- æ¦‚ç‡å¢é•¿æ›´å¹³ç¼“ï¼Œé¿å…è¿‡åº¦æ•æ„Ÿ
- å¹³å‡æ•æ„Ÿæ¦‚ç‡é™ä½

---

### æ–¹æ¡ˆ2ï¼šæ¸…æ´—è¯è¡¨ï¼ˆæœ€æœ‰æ•ˆï¼Œä½†éœ€è¦æ—¶é—´ï¼‰

#### 2.1 ä½¿ç”¨ LLM æ¸…æ´—è¯è¡¨

**å·²æœ‰åŠŸèƒ½**ï¼Œç›´æ¥ä½¿ç”¨ï¼š

```bash
# æ¸…æ´—æ‰€æœ‰ç±»åˆ«çš„è¯è¡¨
python scripts/lexicon_generator.py \
    --clean-lexicon \
    --lexicon-dir configs/lexicons \
    --categories porn politics abuse \
    --clean-batch-size 100 \
    --backup-original

# æ¸…æ´—å•ä¸ªç±»åˆ«ï¼ˆä¾‹å¦‚ï¼Œå…ˆæ¸…æ´—è¯¯æŠ¥æœ€å¤šçš„ç±»åˆ«ï¼‰
python scripts/lexicon_generator.py \
    --clean-lexicon \
    --lexicon-dir configs/lexicons \
    --categories politics \
    --clean-batch-size 100
```

**é¢„æœŸæ•ˆæœ**ï¼š
- åˆ é™¤ 70-85% çš„å™ªå£°è¯
- æ˜¾è‘—æé«˜ Precision
- è¯è¡¨å¤§å°å‡å°‘ï¼ŒåŒ¹é…æ•ˆç‡æå‡ 3-5 å€

#### 2.2 æ‰‹åŠ¨æ£€æŸ¥é«˜é¢‘è¯¯æŠ¥è¯

**æ­¥éª¤**ï¼š
1. è¿è¡Œ `eval_q0.py` æ‰¾å‡ºè¯¯æŠ¥æ ·æœ¬
2. åˆ†æè¿™äº›æ ·æœ¬åŒ¹é…åˆ°çš„è¯
3. æ‰‹åŠ¨åˆ é™¤æ˜æ˜¾è¯¯æŠ¥çš„è¯

**åˆ›å»ºè„šæœ¬ï¼š`scripts/analyze_q0_errors.py`**

```python
"""
åˆ†æ qâ‚€ è¯¯æŠ¥æ ·æœ¬ï¼Œæ‰¾å‡ºé«˜é¢‘è¯¯æŠ¥è¯
"""
import json
from collections import Counter

def analyze_q0_errors(q0_file: str, baseline_file: str):
    """åˆ†æ qâ‚€ è¯¯æŠ¥"""
    # åŠ è½½æ•°æ®
    q0_dict = {}
    baseline_dict = {}
    
    with open(q0_file, 'r', encoding='utf-8') as f:
        for line in f:
            item = json.loads(line)
            q0_dict[item['id']] = item
    
    with open(baseline_file, 'r', encoding='utf-8') as f:
        for line in f:
            item = json.loads(line)
            baseline_dict[item['id']] = item
    
    # æ‰¾å‡ºè¯¯æŠ¥ï¼ˆqâ‚€ é¢„æµ‹æ•æ„Ÿï¼Œä½†å®é™…éæ•æ„Ÿï¼‰
    false_positives = []
    false_positive_words = Counter()
    
    for item_id, q0_item in q0_dict.items():
        if item_id not in baseline_dict:
            continue
        
        q0_label = 1 if q0_item['q0'][1] > 0.5 else 0
        true_label = baseline_dict[item_id]['coarse_label']
        
        if q0_label == 1 and true_label == 0:  # è¯¯æŠ¥
            false_positives.append({
                'id': item_id,
                'text': q0_item.get('text', ''),
                'q0': q0_item['q0'],
                'matched_words': []
            })
            
            # æ”¶é›†åŒ¹é…åˆ°çš„è¯
            if 'q0_details' in q0_item:
                details = q0_item['q0_details']
                for word in details.get('porn_matches', []):
                    false_positive_words[word] += 1
                for word in details.get('politics_matches', []):
                    false_positive_words[word] += 1
                for word in details.get('abuse_matches', []):
                    false_positive_words[word] += 1
    
    # è¾“å‡ºç»“æœ
    print(f"è¯¯æŠ¥æ ·æœ¬æ•°: {len(false_positives)}")
    print(f"\né«˜é¢‘è¯¯æŠ¥è¯ï¼ˆTop 20ï¼‰:")
    for word, count in false_positive_words.most_common(20):
        print(f"  {word}: {count} æ¬¡")
    
    # ä¿å­˜è¯¯æŠ¥æ ·æœ¬
    with open('output/q0_false_positives.jsonl', 'w', encoding='utf-8') as f:
        for item in false_positives[:100]:  # ä¿å­˜å‰100ä¸ª
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    print(f"\nè¯¯æŠ¥æ ·æœ¬å·²ä¿å­˜åˆ°: output/q0_false_positives.jsonl")

if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--q0-file', type=str, required=True)
    parser.add_argument('--baseline-file', type=str, required=True)
    args = parser.parse_args()
    
    analyze_q0_errors(args.q0_file, args.baseline_file)
```

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
python scripts/analyze_q0_errors.py \
    --q0-file data/q0_test.jsonl \
    --baseline-file output/test_with_uncertainty.jsonl
```

---

### æ–¹æ¡ˆ3ï¼šæ”¹è¿›æ¦‚ç‡è®¡ç®—é€»è¾‘ï¼ˆæ›´ä¿å®ˆçš„ç­–ç•¥ï¼‰

#### 3.1 ä½¿ç”¨æ›´ä¿å®ˆçš„æ¦‚ç‡æ˜ å°„

**ä¿®æ”¹ `scripts/q0_builder.py` çš„æ¦‚ç‡è®¡ç®—éƒ¨åˆ†**ï¼š

```python
# åŸä»£ç ï¼ˆç¬¬ 278-279 è¡Œï¼‰
normalized_score = np.tanh(match_score * 10)
p_sensitive = base_sensitive_prob + (max_sensitive_prob - base_sensitive_prob) * (normalized_score + 1) / 2

# æ”¹ä¸ºæ›´ä¿å®ˆçš„ç­–ç•¥
def compute_conservative_prob(match_score, total_matches, text_words, 
                              base_sensitive_prob=0.1, max_sensitive_prob=0.75):
    """
    æ›´ä¿å®ˆçš„æ¦‚ç‡è®¡ç®—ï¼š
    1. è¦æ±‚åŒ¹é…å¯†åº¦è¶³å¤Ÿé«˜ï¼ˆåŒ¹é…è¯æ•° / æ–‡æœ¬é•¿åº¦ï¼‰
    2. ä½¿ç”¨æ›´å¹³ç¼“çš„æ¦‚ç‡å¢é•¿æ›²çº¿
    """
    # è®¡ç®—åŒ¹é…å¯†åº¦
    match_density = total_matches / max(text_words, 1)
    
    # å¦‚æœåŒ¹é…å¯†åº¦å¤ªä½ï¼Œä½¿ç”¨åŸºç¡€æ¦‚ç‡
    if match_density < 0.1:  # åŒ¹é…è¯å æ¯” < 10%
        return base_sensitive_prob
    
    # ä½¿ç”¨ sigmoid å‡½æ•°ï¼Œæ›´å¹³ç¼“
    # sigmoid(x) = 1 / (1 + exp(-k*x))
    # è°ƒæ•´ k ä½¿æ¦‚ç‡å¢é•¿æ›´å¹³ç¼“
    k = 3.0  # ä»åŸæ¥çš„ 10 é™ä½åˆ° 3
    sigmoid_score = 1 / (1 + np.exp(-k * match_score))
    
    # æ˜ å°„åˆ° [base_sensitive_prob, max_sensitive_prob]
    p_sensitive = base_sensitive_prob + (max_sensitive_prob - base_sensitive_prob) * sigmoid_score
    
    return p_sensitive
```

#### 3.2 åŸºäºåŒ¹é…æ•°é‡çš„é˜ˆå€¼ç­–ç•¥

**ä¿®æ”¹ `scripts/q0_builder.py`**ï¼š

```python
# åœ¨ compute_q0 å‡½æ•°ä¸­ï¼Œä¿®æ”¹æ¦‚ç‡è®¡ç®—é€»è¾‘
if total_matches < min_matches_for_sensitive:
    p_sensitive = base_sensitive_prob
elif total_matches == 1:
    # åªåŒ¹é…åˆ° 1 ä¸ªè¯ï¼Œä½¿ç”¨è¾ƒä½æ¦‚ç‡
    p_sensitive = base_sensitive_prob + (max_sensitive_prob - base_sensitive_prob) * 0.3
elif total_matches == 2:
    # åŒ¹é…åˆ° 2 ä¸ªè¯ï¼Œä½¿ç”¨ä¸­ç­‰æ¦‚ç‡
    p_sensitive = base_sensitive_prob + (max_sensitive_prob - base_sensitive_prob) * 0.6
else:
    # åŒ¹é…åˆ° 3 ä¸ªæˆ–æ›´å¤šè¯ï¼Œä½¿ç”¨è¾ƒé«˜æ¦‚ç‡
    normalized_score = np.tanh(match_score * 5)  # é™ä½ç¼©æ”¾å› å­
    p_sensitive = base_sensitive_prob + (max_sensitive_prob - base_sensitive_prob) * (normalized_score + 1) / 2
```

---

### æ–¹æ¡ˆ4ï¼šæ”¹è¿›åŒ¹é…ç­–ç•¥

#### 4.1 è¦æ±‚å¤šä¸ªç±»åˆ«åŒæ—¶åŒ¹é…

**ä¿®æ”¹ `scripts/q0_builder.py`**ï¼š

```python
# åœ¨ compute_q0 å‡½æ•°ä¸­ï¼Œæ·»åŠ å¤šç±»åˆ«åŒ¹é…è¦æ±‚
porn_matches = lexicon_matches.get('porn', [])
politics_matches = lexicon_matches.get('politics', [])
abuse_matches = lexicon_matches.get('abuse', [])

# è¦æ±‚è‡³å°‘ 2 ä¸ªç±»åˆ«éƒ½æœ‰åŒ¹é…ï¼Œæˆ–è€…å•ä¸ªç±»åˆ«åŒ¹é…æ•° >= 3
categories_with_matches = sum([
    len(porn_matches) > 0,
    len(politics_matches) > 0,
    len(abuse_matches) > 0
])

if categories_with_matches < 2 and total_matches < 3:
    # ä¸æ»¡è¶³æ¡ä»¶ï¼Œä½¿ç”¨åŸºç¡€æ¦‚ç‡
    p_sensitive = base_sensitive_prob
else:
    # æ­£å¸¸è®¡ç®—
    ...
```

#### 4.2 ä½¿ç”¨è¯è¾¹ç•ŒåŒ¹é…ï¼ˆé¿å…å­ä¸²åŒ¹é…ï¼‰

**ä¿®æ”¹ `scripts/q0_builder.py` çš„ `match_lexicon` å‡½æ•°**ï¼š

```python
import re

def match_lexicon_with_word_boundary(text: str, lexicons: Dict[str, Set[str]]):
    """
    ä½¿ç”¨è¯è¾¹ç•ŒåŒ¹é…ï¼Œé¿å…å­ä¸²è¯¯åŒ¹é…
    ä¾‹å¦‚ï¼š"è¿è¡£è£™" ä¸ä¼šåŒ¹é…åˆ° "è£™"
    """
    matches = {category: [] for category in lexicons.keys()}
    
    for category, words in lexicons.items():
        for word in words:
            # ä½¿ç”¨è¯è¾¹ç•Œæ­£åˆ™
            pattern = r'\b' + re.escape(word) + r'\b'
            if re.search(pattern, text, re.IGNORECASE):
                matches[category].append(word)
    
    return matches
```

---

## ğŸ¯ æ¨èæ”¹è¿›æµç¨‹

### ç¬¬ä¸€æ­¥ï¼šè¯„ä¼°å½“å‰ qâ‚€ è´¨é‡

```bash
# 1. åˆ›å»ºè¯„ä¼°è„šæœ¬ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
# 2. è¿è¡Œè¯„ä¼°
python scripts/eval_q0.py \
    --q0-file data/q0_test.jsonl \
    --baseline-file output/test_with_uncertainty.jsonl
```

### ç¬¬äºŒæ­¥ï¼šå¿«é€Ÿè°ƒæ•´å‚æ•°ï¼ˆç«‹å³ç”Ÿæ•ˆï¼‰

```bash
# ä¿®æ”¹ config.yaml æˆ–ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
python scripts/q0_builder.py \
    --max-sensitive-prob 0.75 \
    --min-matches-for-sensitive 2 \
    --politics-weight 0.6 \
    --abuse-weight 0.5 \
    --datasets test

# é‡æ–°è¯„ä¼°
python scripts/eval_q0.py \
    --q0-file data/q0_test.jsonl \
    --baseline-file output/test_with_uncertainty.jsonl
```

### ç¬¬ä¸‰æ­¥ï¼šæ¸…æ´—è¯è¡¨ï¼ˆå¦‚æœå‚æ•°è°ƒæ•´ä¸å¤Ÿï¼‰

```bash
# æ¸…æ´—è¯è¡¨
python scripts/lexicon_generator.py \
    --clean-lexicon \
    --lexicon-dir configs/lexicons \
    --categories porn politics abuse \
    --backup-original

# é‡æ–°ç”Ÿæˆ qâ‚€
python scripts/q0_builder.py --datasets test

# é‡æ–°è¯„ä¼°
python scripts/eval_q0.py \
    --q0-file data/q0_test.jsonl \
    --baseline-file output/test_with_uncertainty.jsonl
```

### ç¬¬å››æ­¥ï¼šåˆ†æè¯¯æŠ¥å¹¶æ‰‹åŠ¨ä¼˜åŒ–

```bash
# åˆ†æè¯¯æŠ¥
python scripts/analyze_q0_errors.py \
    --q0-file data/q0_test.jsonl \
    --baseline-file output/test_with_uncertainty.jsonl

# æŸ¥çœ‹é«˜é¢‘è¯¯æŠ¥è¯ï¼Œæ‰‹åŠ¨åˆ é™¤
# ç„¶åé‡æ–°ç”Ÿæˆ qâ‚€ å’Œè¯„ä¼°
```

### ç¬¬äº”æ­¥ï¼šé‡æ–°è¿è¡Œ Day7-Day9

```bash
# é‡æ–°è¿è¡Œ Day7ï¼ˆä½¿ç”¨æ–°çš„ qâ‚€ï¼‰
python scripts/emg_bucket_search.py

# é‡æ–°è¿è¡Œ Day8
python scripts/emg_fit_alpha_u.py

# é‡æ–°è¿è¡Œ Day9
python scripts/eval_emg.py
```

---

## ğŸ“Š é¢„æœŸæ”¹è¿›æ•ˆæœ

### ç›®æ ‡æŒ‡æ ‡

- **qâ‚€ Precision**: ä» < 0.70 æå‡åˆ° â‰¥ 0.75
- **qâ‚€ F1**: ä» < 0.75 æå‡åˆ° â‰¥ 0.80
- **å¹³å‡æ•æ„Ÿæ¦‚ç‡**: ä» 0.82 é™ä½åˆ° 0.65-0.70
- **EMG F1**: ä» 88.36% æå‡åˆ° â‰¥ 89.13%ï¼ˆè¶…è¿‡ baselineï¼‰

### æ”¹è¿›ä¼˜å…ˆçº§

1. **ğŸ¥‡ è°ƒæ•´å‚æ•°**ï¼ˆæœ€ç®€å•ï¼Œç«‹å³ç”Ÿæ•ˆï¼‰
   - é™ä½ `max_sensitive_prob` åˆ° 0.75
   - æé«˜ `min_matches_for_sensitive` åˆ° 2
   - è°ƒæ•´ç±»åˆ«æƒé‡

2. **ğŸ¥ˆ æ¸…æ´—è¯è¡¨**ï¼ˆæœ€æœ‰æ•ˆï¼Œä½†éœ€è¦æ—¶é—´ï¼‰
   - ä½¿ç”¨ LLM æ¸…æ´—ï¼Œåˆ é™¤ 70-85% å™ªå£°è¯

3. **ğŸ¥‰ æ”¹è¿›æ¦‚ç‡è®¡ç®—**ï¼ˆéœ€è¦ä¿®æ”¹ä»£ç ï¼‰
   - æ›´ä¿å®ˆçš„æ¦‚ç‡æ˜ å°„
   - åŸºäºåŒ¹é…æ•°é‡çš„é˜ˆå€¼ç­–ç•¥

4. **æ”¹è¿›åŒ¹é…ç­–ç•¥**ï¼ˆéœ€è¦ä¿®æ”¹ä»£ç ï¼‰
   - è¦æ±‚å¤šç±»åˆ«åŒ¹é…
   - è¯è¾¹ç•ŒåŒ¹é…

---

**å»ºè®®**ï¼šå…ˆå°è¯•æ–¹æ¡ˆ1ï¼ˆè°ƒæ•´å‚æ•°ï¼‰ï¼Œå¦‚æœä¸å¤Ÿå†å°è¯•æ–¹æ¡ˆ2ï¼ˆæ¸…æ´—è¯è¡¨ï¼‰ï¼Œæœ€åè€ƒè™‘æ–¹æ¡ˆ3å’Œ4ï¼ˆä¿®æ”¹ä»£ç ï¼‰ã€‚

