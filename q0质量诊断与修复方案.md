# q0质量诊断与修复方案

**日期**：2025-12-15  
**问题**：词表优化后q0质量显著下降，导致Day7结果异常

---

## 📊 q0质量评估结果

### 当前q0质量（词表优化后）

| 指标 | 数值 | 评估 |
|------|------|------|
| **Precision** | 88.70% | ✅ 良好（误报少） |
| **Recall** | **18.37%** | ❌ **极低（漏检严重）** |
| **F1** | 30.44% | ❌ 很低 |
| **Accuracy** | 45.59% | ❌ 低于随机猜测（50%） |
| **平均敏感概率** | 0.1812 | ❌ 过低（< 0.50） |

### 混淆矩阵分析

- **TP (真阳性)**: 589（正确识别敏感）
- **FN (假阴性)**: **2,617**（漏检敏感样本，**严重问题**）
- **TN (真阴性)**: 1,667（正确识别非敏感）
- **FP (假阳性)**: 75（误报，较少）

**关键发现**：
- ✅ Precision高（88.70%）：匹配到的词质量好，很少误报
- ❌ **Recall极低（18.37%）**：漏检了**81.63%**的敏感样本
- ❌ **平均敏感概率过低（0.1812）**：大部分样本的q0敏感概率都很低

---

## 🔍 问题根因分析

### 根本原因：词表优化过度，匹配率大幅下降

**词表变化**：
- 优化前：36,012个词
- 优化后：5,875个词（-83.7%）

**影响**：
1. **匹配词数减少**：很多敏感样本因为匹配不到词而无法被q0识别
2. **min_matches_for_sensitive=2太严格**：词表变小后，很难达到2个匹配
3. **平均敏感概率过低（0.1812）**：大部分样本匹配不到词或匹配数不足，导致敏感概率接近base_prob（0.1）

### 为什么导致Day7结果异常？

#### 高u样本（Bucket 3, 4：α*=1.00）

**理论预期**：高u时应该信任知识（α→0）

**实际情况**：
- 模型不确定（高u），期望q0帮助
- 但q0召回率只有18.37%，漏检了81.63%的敏感样本
- **使用q0反而误导模型**（因为大部分敏感样本q0都判断为0.1左右的低概率）
- 结果：只能完全信任模型（α=1.0）

#### 低u样本（Bucket 0：α*=0.50）

**理论预期**：低u时应该信任模型（α→1）

**实际情况**：
- 模型已经很确定（低u），不需要太多q0帮助
- q0虽然质量不好，但影响相对较小
- 结果：α=0.50（平衡）

---

## 💡 修复方案

### 方案1：降低匹配要求（**推荐，快速尝试**）

**调整q0参数以适应新的词表规模**：

```yaml
# configs/config.yaml
q0:
  max_sensitive_prob: 0.75  # 保持
  min_matches_for_sensitive: 1  # 从2降低到1（词表小了，降低要求）
  base_sensitive_prob: 0.1  # 保持
  # 其他参数保持不变
```

**预期效果**：
- 提高召回率（更多样本能匹配到至少1个词）
- 提高平均敏感概率
- 可能略微降低Precision（但Precision已经很高，88.70%，可以承受）

**实施步骤**：
1. 修改`configs/config.yaml`
2. 重新运行Day6生成q0
3. 重新评估q0质量
4. 如果改善，重新运行Day7

### 方案2：降低base_prob或提高匹配词权重（备选）

如果方案1效果不够，可以尝试：

```yaml
q0:
  base_sensitive_prob: 0.15  # 从0.1提高到0.15（增加基础敏感概率）
  # 或调整tanh缩放因子，使匹配更容易触发高概率
```

### 方案3：恢复部分被删的词（如果确认误删）

如果诊断确认词表过度删除，可以：
1. 分析被删词中是否有高频匹配词
2. 恢复部分有用词
3. 重新优化词表（更保守的策略）

---

## 🎯 推荐执行步骤

### 步骤1：调整参数（方案1）

```bash
# 在本地修改config.yaml
# min_matches_for_sensitive: 2 → 1

# 提交到git
git add configs/config.yaml
git commit -m "调整q0参数：降低匹配要求以适应优化后的词表"
git push origin main

# 云端拉取
cd /mnt/workspace/EMG-PKRI
git pull origin main
```

### 步骤2：重新生成q0

```bash
python scripts/q0_builder.py --datasets train dev test
```

### 步骤3：重新评估q0质量

```bash
python scripts/eval_q0.py \
    --q0-file data/q0_dev.jsonl \
    --baseline-file output/dev_with_uncertainty.jsonl
```

**目标指标**：
- ✅ Recall > 40%（至少比当前18.37%提高一倍）
- ✅ 平均敏感概率 > 0.30（至少比当前0.1812提高）
- ✅ Precision保持在>75%（可以略微降低）

### 步骤4：如果q0质量改善，重新运行Day7

```bash
python scripts/emg_bucket_search.py
```

**预期结果**：
- Bucket 3, 4的α*应该从1.00降低（接近0.5-0.75）
- 总体趋势应该更接近理论预期

---

## 📋 对比：修复前后预期

### 修复前（当前）

| Bucket | u_mean | alpha_star | 说明 |
|--------|--------|------------|------|
| 0 | 0.016 | 0.50 | 低u但α不够大 |
| 3 | 0.349 | **1.00** ❌ | 高u但完全信任模型 |
| 4 | 0.451 | **1.00** ❌ | 高u但完全信任模型 |

### 修复后（预期）

| Bucket | u_mean | alpha_star | 说明 |
|--------|--------|------------|------|
| 0 | 0.016 | 0.75-1.0 | ✅ 低u，信任模型 |
| 3 | 0.349 | 0.25-0.5 | ✅ 高u，信任知识 |
| 4 | 0.451 | 0.0-0.5 | ✅ 高u，信任知识 |

---

## ⚠️ 注意事项

1. **Precision可能略微下降**：降低匹配要求会提高召回率，但可能增加误报。当前Precision很高（88.70%），可以承受一定下降。

2. **需要重新运行Day6和Day7**：参数调整后必须重新生成q0和搜索α*。

3. **如果方案1不够**：可以考虑方案2或方案3，但需要更多分析和测试。

---

## 📝 总结

**问题诊断**：
- ✅ q0 Precision良好（88.70%），但Recall极低（18.37%）
- ✅ 根本原因：词表优化后匹配率大幅下降，导致漏检严重
- ✅ 这解释了Day7结果异常（高u时只能信任模型）

**修复方案**：
- ✅ **推荐**：降低`min_matches_for_sensitive`从2到1
- ✅ 预期：提高召回率，改善q0质量，Day7结果应该更符合理论预期

