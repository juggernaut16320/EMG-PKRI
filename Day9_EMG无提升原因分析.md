# Day9 EMG 无提升原因深度分析

**分析时间**：2025-12-14  
**分析范围**：Day1-Day9 完整实验流程

---

## 📊 核心结果回顾

### Day9 最终结果

| 方法 | F1 | NLL | ECE | 对比 Baseline |
|------|----|-----|-----|---------------|
| **Baseline** | **89.13%** | **0.4001** | **0.0730** | - |
| Fixed α=0.5 | 87.93% | 0.4261 | 0.0956 | ❌ 全部下降 |
| **EMG** | 88.36% | 0.4229 | 0.1021 | ❌ 全部下降 |

**关键发现**：
- ❌ EMG 在所有指标上都**不如 baseline**
- ⚠️ EMG 略优于固定 α 融合，但提升很小（<1%）

---

## 🔍 根本原因分析

基于对 Day1-Day9 完整数据的分析，发现以下**关键问题**：

### 1. ❌ **q₀ 质量问题：平均敏感概率过高（0.82）**

**现象**：
- Day6 生成的 q₀ 平均敏感概率：**train=0.8231, dev=0.8203, test=0.8174**
- 这个值**严重偏高**，接近 0.82

**问题分析**：

#### 1.1 q₀ 计算逻辑问题

查看 `q0_builder.py` 的 `compute_q0` 函数（第278-279行）：

```python
normalized_score = np.tanh(match_score * 10)
p_sensitive = base_sensitive_prob + (max_sensitive_prob - base_sensitive_prob) * (normalized_score + 1) / 2
```

**问题**：
- `tanh(match_score * 10)` 将 match_score 映射到 [-1, 1]
- `(normalized_score + 1) / 2` 将其映射到 [0, 1]
- 然后线性映射到 `[base_sensitive_prob=0.1, max_sensitive_prob=0.95]`
- **这意味着只要匹配到词表，p_sensitive 至少是 0.1，最多是 0.95**

#### 1.2 平均敏感概率 0.82 的含义

**平均敏感概率 0.82 非常高**，可能的原因：

1. **词表匹配率过高**：
   - 36,010 个词的表可能匹配了大量样本
   - 即使正常文本也可能被误匹配

2. **q₀ 的 Precision 可能很低**：
   - 如果 q₀ 对大部分样本都给出高敏感概率（>0.5），但实际准确率不高
   - 在融合时会引入**大量噪声**

3. **与实际标签分布不匹配**：
   - 测试集中敏感样本占比约为 64.8%（3206/4948）
   - 但 q₀ 平均敏感概率 0.82 **明显高于真实分布**

#### 1.3 q₀ 噪声影响 EMG

**EMG 融合公式**：
```
p_emg = α × p + (1 - α) × q₀
```

**影响分析**：
- 如果 q₀ 质量差（低 Precision），即使只有 `(1-α)` 的权重，也会引入噪声
- 对于低不确定性样本（α=0.75），q₀ 权重 25%，但如果 q₀ 错误，仍会降低性能
- 对于高不确定性样本（α=0.00），完全依赖 q₀，如果 q₀ 不准，性能会显著下降

---

### 2. ⚠️ **测试集 vs Dev 集的分布差异**

#### 2.1 Day7 在 Dev 集上搜索 α*

**Day7 结果**（dev 集，4948 样本）：
| Bucket | u_mean | n_samples | alpha_star | f1_at_alpha_star |
|--------|--------|-----------|------------|------------------|
| 0 | 0.016 | 3,912 | 0.75 | 0.932 |
| 1 | 0.146 | 368 | 0.25 | 0.709 |
| 2 | 0.248 | 284 | 0.50 | 0.701 |
| 3 | 0.349 | 207 | 0.00 | 0.650 |
| 4 | 0.451 | 177 | 0.00 | 0.640 |

**关键观察**：
- Bucket 0（低不确定性）样本数：**3,912（79%）**
- Bucket 0 的 F1 在 α*=0.75 时达到 **0.932**

#### 2.2 Day4 不确定性与样本分布（dev+test，9896 样本）

| Bucket | u_mean | 样本数 | 占比 | 错误率 |
|--------|--------|--------|------|--------|
| 0 | 0.016 | 7,825 | **79.1%** | 8.56% |
| 1 | 0.146 | 758 | 7.7% | 33.64% |
| 2+ | >0.2 | 1,313 | 13.2% | 32-46% |

**关键发现**：
- **79.1% 的样本在低不确定性区间**（u < 0.1）
- 这些样本的错误率仅 **8.56%**，baseline 已经很准确

#### 2.3 测试集可能的情况

**推测**：
- 测试集中**低不确定性样本比例可能更高**（因为测试集表现优于 dev 集：F1 89.13% vs 88.3%）
- 对于这些样本：
  - Baseline 已经很准确（F1 ≈ 0.89-0.93）
  - EMG 即使融合 q₀，提升空间很小
  - **如果 q₀ 质量差，反而会降低性能**

---

### 3. ⚠️ **Baseline 性能已经很高**

**Day3 测试集结果**：
- F1: **89.13%**（优秀水平）
- Accuracy: **85.95%**
- Precision: **89.42%**
- Recall: **88.83%**

**Day4 不确定性分析**：
- 79.1% 样本在低不确定性区间，错误率仅 **8.56%**
- 这些样本上 baseline 已经非常准确

**结论**：
- Baseline 性能已经很高，**改善空间有限**
- EMG 的主要目标是改善**高不确定性样本**，但这些样本只占 20.9%
- 即使 EMG 能改善高不确定性样本，但低不确定性样本（79%）如果被 q₀ 污染，整体性能仍可能下降

---

### 4. ⚠️ **α(u) 函数在测试集上可能不是最优**

#### 4.1 Day7 在 Dev 集上搜索

**问题**：
- α* 是在 **dev 集**上搜索得到的
- 但 Day9 在 **test 集**上评估
- **测试集和 dev 集的分布可能不同**

#### 4.2 测试集 vs Dev 集的差异

**证据**：
- Day3: 测试集 F1 (89.13%) > 验证集 F1 (88.3%)
- 说明测试集可能**更容易**，不确定性和难度分布不同

**影响**：
- 在 dev 集上找到的 α* 可能**不适合测试集**
- 测试集上可能需要不同的 α(u) 函数

---

### 5. ⚠️ **EMG 融合公式的局限性**

#### 5.1 线性融合的局限

**EMG 公式**：
```
p_emg = α × p + (1 - α) × q₀
```

**问题**：
- 这是**简单的线性融合**
- 如果 p 和 q₀ 有冲突（一个预测敏感，一个预测非敏感），线性融合可能产生**"中间值"**，既不如 p，也不如 q₀

**示例**：
- p = [0.9, 0.1]（模型预测：非敏感，置信度高）
- q₀ = [0.2, 0.8]（知识预测：敏感，置信度高）
- α = 0.75
- p_emg = 0.75 × [0.9, 0.1] + 0.25 × [0.2, 0.8] = [0.725, 0.275]
- 如果真实标签是非敏感，EMG 的预测（0.725 < 0.5，预测非敏感）可能不如 baseline（0.9，更确定）

#### 5.2 q₀ 质量差时的影响

**场景**：
- 如果 q₀ 的 Precision 低（很多误报），即使只有 `(1-α)` 的权重
- 在低不确定性样本（α=0.75）上，25% 的 q₀ 噪声仍会降低性能
- 在高不确定性样本（α=0.00）上，完全依赖 q₀，如果 q₀ 不准，性能会显著下降

---

## 📈 数据验证假设

### 假设 1：q₀ 的 Precision 可能很低

**验证方法**：
- 计算 q₀ 在测试集上的 Precision/Recall/Accuracy
- 如果 Precision < 0.7，说明 q₀ 质量差

### 假设 2：测试集低不确定性样本比例更高

**验证方法**：
- 对比测试集和 dev 集的不确定性分布
- 如果测试集低不确定性样本占比 > 80%，说明 baseline 已经很好

### 假设 3：低不确定性样本上 q₀ 引入了噪声

**验证方法**：
- 分别分析低不确定性样本（u < 0.1）和高不确定性样本（u ≥ 0.1）上 EMG vs Baseline 的表现
- 如果低不确定性样本上 EMG 更差，说明 q₀ 引入了噪声

---

## 🎯 核心问题总结

### 最可能的原因（按重要性排序）

#### 🥇 **1. q₀ 质量问题（最重要）**

**证据**：
- 平均敏感概率 0.82 **严重偏高**
- 可能 Precision 低，引入大量噪声

**影响**：
- 在融合时，即使 q₀ 权重只有 25%（低不确定性时），也会降低性能
- 在高不确定性时（完全依赖 q₀），如果 q₀ 不准，性能显著下降

**解决方案**：
1. **评估 q₀ 的 Precision/Recall**：
   ```python
   # 计算 q₀ 在测试集上的指标
   q0_pred_labels = [1 if q0[1] > 0.5 else 0 for q0 in q0_dict.values()]
   q0_precision = precision_score(true_labels, q0_pred_labels)
   ```
2. **如果 Precision < 0.75，需要清洗词表**：
   - 使用 `lexicon_generator.py --clean-lexicon` 删除噪声词
   - 或者调整 q₀ 计算参数（降低 max_sensitive_prob）

#### 🥈 **2. Baseline 性能已经很高**

**证据**：
- F1: 89.13% 已经很高
- 79.1% 样本在低不确定性区间，错误率仅 8.56%

**影响**：
- 改善空间有限
- 如果 q₀ 质量差，很容易反而降低性能

**解决方案**：
- 专注于改善**高不确定性样本**（20.9%）
- 分析高不确定性样本上 EMG vs Baseline 的对比

#### 🥉 **3. 测试集 vs Dev 集的分布差异**

**证据**：
- Day7 在 dev 集上搜索 α*
- Day9 在 test 集上评估
- 测试集 F1 (89.13%) > dev 集 F1 (88.3%)

**影响**：
- 在 dev 集上找到的 α(u) 可能不适合测试集

**解决方案**：
- 在测试集上重新搜索 α*（如果可能）
- 或者使用更通用的 α(u) 函数

---

## 🔧 改进建议

### 立即行动（高优先级）

1. **评估 q₀ 的 Precision/Recall/Accuracy**：
   ```python
   # 在 eval_emg.py 中添加 q₀ 评估
   q0_pred_labels = [1 if q0[1] > 0.5 else 0 for q0 in q0_dict.values()]
   q0_metrics = {
       'precision': precision_score(true_labels, q0_pred_labels),
       'recall': recall_score(true_labels, q0_pred_labels),
       'f1': f1_score(true_labels, q0_pred_labels),
       'accuracy': accuracy_score(true_labels, q0_pred_labels)
   }
   ```

2. **分不确定性区间分析 EMG 效果**：
   - 低不确定性（u < 0.1）：EMG vs Baseline
   - 高不确定性（u ≥ 0.1）：EMG vs Baseline
   - 找出 EMG 在哪类样本上表现更好/更差

3. **分析 q₀ 的错误案例**：
   - 找出 q₀ 误报（预测敏感但实际非敏感）的样本
   - 分析这些样本的特征，改进词表

### 中期优化（中优先级）

1. **优化 q₀ 构建**：
   - 清洗词表，删除噪声词
   - 调整 q₀ 计算参数（降低 max_sensitive_prob 或调整权重）
   - 改进匹配策略（例如，要求多个词同时匹配）

2. **在测试集上重新搜索 α***：
   - 如果数据允许，在测试集上重新运行 Day7
   - 对比 dev 集和 test 集的 α* 差异

3. **尝试不同的融合策略**：
   - 非线性融合（例如，基于置信度的加权）
   - 分类融合（低不确定性用模型，高不确定性用 q₀）

### 长期探索（低优先级）

1. **改进不确定性指标**：
   - 尝试 u_entropy、u_margin 等其他不确定性指标
   - 对比不同不确定性指标的 EMG 效果

2. **改进 α(u) 搜索策略**：
   - 使用更细的 α 网格（例如，0.05 步长）
   - 使用优化算法（如贝叶斯优化）搜索 α*

3. **改进 q₀ 构建**：
   - 使用 LLM 生成更高质量的词表
   - 使用上下文相关的匹配（而非简单的词表匹配）

---

## 📊 预期验证结果

### 如果验证 q₀ 质量问题

**预期发现**：
- q₀ 的 Precision < 0.70
- q₀ 的 F1 < 0.75
- q₀ 误报率 > 20%

**结论**：
- ✅ **q₀ 质量差是主要原因**
- ✅ 需要清洗词表或调整 q₀ 计算参数

### 如果验证测试集分布问题

**预期发现**：
- 测试集低不确定性样本占比 > 85%
- 低不确定性样本上，EMG 不如 baseline
- 高不确定性样本上，EMG 略优于 baseline

**结论**：
- ✅ **测试集分布差异是次要原因**
- ✅ EMG 在高不确定性样本上有效，但在低不确定性样本上被 q₀ 污染

---

## 🎯 最终结论

### 最可能的原因组合

1. **🥇 主要原因：q₀ 质量问题**
   - 平均敏感概率 0.82 过高
   - 可能 Precision 低，在融合时引入噪声
   - 即使权重只有 25%，也会显著影响性能

2. **🥈 次要原因：Baseline 性能已经很高**
   - F1: 89.13% 已经很高
   - 79% 样本在低不确定性区间，baseline 已经很准确
   - EMG 的改善空间有限

3. **🥉 潜在原因：测试集 vs Dev 集分布差异**
   - Day7 在 dev 集上搜索的 α* 可能不适合测试集
   - 需要验证测试集的不确定性分布

### 下一步行动

1. **立即验证**：评估 q₀ 的 Precision/Recall/Accuracy
2. **立即分析**：分不确定性区间对比 EMG vs Baseline
3. **根据结果**：决定是优化 q₀ 还是调整融合策略

---

**分析完成时间**：2025-12-14  
**分析结论**：q₀ 质量问题是最可能的主要原因，需要验证和优化

