# 知识阈值门控设计方案

**问题**：知识阈值门控的阈值不应该硬编码（如0.6），而应该通过数据学习出来。

---

## 📊 当前问题

### 硬编码方案的问题
- ❌ 固定阈值（如0.6）是经验值，缺乏数据支撑
- ❌ 不同数据集的最佳阈值可能不同
- ❌ 无法验证阈值选择的合理性

---

## ✅ 改进方案：基于验证集的阈值搜索

### 方案概述

**核心思想**：类似 Day7 的 α* 搜索，在验证集上搜索最优的知识阈值。

### 实现步骤

#### 1. 阈值搜索逻辑

```python
def search_knowledge_threshold(
    baseline_results: Dict[str, Dict],
    q0_dict: Dict[str, List[float]],
    alpha_lut: Dict[str, List[float]],
    threshold_grid: List[float] = [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
) -> Tuple[float, Dict]:
    """
    搜索最优的知识阈值
    
    规则：当 max(q₀) < threshold 时，设置 α=1.0（完全信任模型）
    否则，使用原来的 α(u)
    
    Args:
        threshold_grid: 候选阈值列表
        
    Returns:
        (最优阈值, 所有阈值的指标字典)
    """
    threshold_metrics = {}
    best_threshold = None
    best_f1 = -float('inf')
    
    for threshold in threshold_grid:
        # 对每个样本应用阈值门控
        metrics = evaluate_with_threshold(
            baseline_results, q0_dict, alpha_lut, threshold
        )
        threshold_metrics[threshold] = metrics
        
        if metrics['f1'] > best_f1:
            best_f1 = metrics['f1']
            best_threshold = threshold
    
    return best_threshold, threshold_metrics
```

#### 2. 门控逻辑

```python
def apply_knowledge_threshold_gating(
    p: List[float],
    q0: List[float],
    u: float,
    alpha_lut: Dict[str, List[float]],
    knowledge_threshold: float
) -> List[float]:
    """
    应用知识阈值门控的EMG融合
    
    Args:
        knowledge_threshold: 知识阈值（学习得到）
        
    规则：
    - 如果 max(q₀) < knowledge_threshold → α=1.0（完全信任模型）
    - 否则 → 使用 α(u) 的正常融合
    """
    max_q0 = max(q0)
    
    if max_q0 < knowledge_threshold:
        # 知识太弱，完全信任模型
        alpha = 1.0
    else:
        # 知识足够强，使用正常的 α(u)
        alpha = lookup_alpha(u, alpha_lut)
    
    return compute_emg_fusion(p, q0, alpha)
```

#### 3. 与一致性门控结合（可选）

```python
def apply_gating_strategies(
    p: List[float],
    q0: List[float],
    u: float,
    alpha_lut: Dict[str, List[float]],
    knowledge_threshold: float,
    use_consistency_gating: bool = True
) -> List[float]:
    """
    应用多种门控策略
    
    规则（按优先级）：
    1. 知识阈值门控：max(q₀) < threshold → α=1.0（完全信任模型）
    2. 一致性门控：argmax(p) != argmax(q₀) → α=1.0（完全信任模型，避免q₀带偏）
    3. 否则：使用 α(u) 的正常融合
    """
    max_q0 = max(q0)
    
    # 优先级1：知识阈值门控
    if max_q0 < knowledge_threshold:
        alpha = 1.0
    # 优先级2：一致性门控（如果启用）
    elif use_consistency_gating and np.argmax(p) != np.argmax(q0):
        alpha = 1.0  # 不一致时不信任q₀，完全信任模型
    # 优先级3：正常融合
    else:
        alpha = lookup_alpha(u, alpha_lut)
    
    return compute_emg_fusion(p, q0, alpha)
```

---

## 🔧 实施建议

### 方案A：独立搜索知识阈值（推荐）

**优点**：
- 简单清晰，易于实现和验证
- 可以单独评估知识阈值门控的效果
- 与现有Day7/Day8流程兼容

**实施步骤**：
1. 创建新脚本 `search_knowledge_threshold.py`
2. 在 dev 集上搜索最优阈值
3. 保存最优阈值到配置文件或单独文件
4. 修改 `eval_emg.py` 使用学习到的阈值

**工作量**：2-3小时

### 方案B：与α(u)联合优化（更复杂）

**优点**：
- 更系统，同时优化两个参数
- 可能找到更优的组合

**缺点**：
- 实现复杂（二维搜索：threshold × alpha_grid）
- 计算量大

**实施步骤**：
1. 修改 `emg_bucket_search.py`，加入阈值搜索
2. 对每个bucket和每个阈值组合进行搜索

**工作量**：4-6小时

---

## 📊 预期效果

### 搜索过程输出示例

```
搜索最优知识阈值...
  threshold=0.4: F1=0.8845, NLL=0.3902
  threshold=0.5: F1=0.8867, NLL=0.3889
  threshold=0.6: F1=0.8873, NLL=0.3878 ✅
  threshold=0.7: F1=0.8856, NLL=0.3895
  threshold=0.8: F1=0.8821, NLL=0.3921
  threshold=0.9: F1=0.8799, NLL=0.3945

✓ 最优阈值 = 0.62（F1=0.8873）
```

### 可能的结果

1. **如果最优阈值接近0.5-0.7**：说明知识阈值门控有效
2. **如果最优阈值接近0.9**：说明大部分q₀都足够强，不需要门控
3. **如果最优阈值接近0.4**：说明需要更激进的过滤弱知识

---

## ✅ 推荐实施方案

**建议采用方案A（独立搜索）**：

1. **先实施知识阈值搜索**（2-3小时）
   - 创建搜索脚本
   - 在dev集上搜索最优阈值
   - 验证效果

2. **再考虑一致性门控**（1-2小时）
   - 评估是否需要
   - 如果效果好，可以结合使用

3. **最终集成到eval_emg.py**（1小时）
   - 使用学习到的阈值
   - 重新评估效果

---

## 🎯 总结

**用户的观点完全正确**：知识阈值门控的阈值应该通过数据学习，而不是硬编码。

**推荐实现方式**：在验证集上搜索最优阈值（类似Day7的α*搜索），这样可以：
- ✅ 有数据支撑
- ✅ 可复现、可验证
- ✅ 易于理解和解释

