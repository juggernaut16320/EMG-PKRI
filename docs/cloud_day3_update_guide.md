# äº‘ä¸Š Day3 å¢é‡æ›´æ–°å’Œæ•°æ®éªŒè¯æŒ‡å—

> **ç›®æ ‡**ï¼šåœ¨äº‘æœåŠ¡å™¨ä¸Šä» git å¢é‡æ›´æ–°ä»£ç ï¼Œå¹¶å®Œæˆ Day3 çš„æ•°æ®éªŒè¯

---

## ğŸ“‹ å‰ç½®æ¡ä»¶

- âœ… äº‘æœåŠ¡å™¨ä¸Šå·² clone Day2 çš„ä»£ç 
- âœ… å·²æ¿€æ´» conda ç¯å¢ƒï¼š`conda activate emgpkri`
- âœ… å·²å®‰è£…æ‰€æœ‰ä¾èµ–ï¼š`pip install -r requirements.txt`
- âœ… Day2 çš„ baseline æ¨¡å‹å·²è®­ç»ƒå®Œæˆï¼ˆ`checkpoints/baseline-lora/`ï¼‰
- âœ… æ•°æ®æ–‡ä»¶å·²å‡†å¤‡å¥½ï¼ˆ`data/test.jsonl`ï¼Œå¯é€‰ï¼š`data/hard_eval_set.jsonl`ï¼‰

---

## ğŸ”„ æ­¥éª¤ 1ï¼šä» Git å¢é‡æ›´æ–°ä»£ç 

### 1.1 è¿›å…¥é¡¹ç›®ç›®å½•

```bash
cd /path/to/your/project  # æ›¿æ¢ä¸ºä½ çš„é¡¹ç›®è·¯å¾„
```

### 1.2 æ£€æŸ¥å½“å‰åˆ†æ”¯å’ŒçŠ¶æ€

```bash
git status
git branch
```

### 1.3 æ‹‰å–æœ€æ–°ä»£ç 

```bash
# æ‹‰å–è¿œç¨‹æœ€æ–°ä»£ç 
git fetch origin

# æŸ¥çœ‹è¿œç¨‹æ›´æ–°å†…å®¹
git log HEAD..origin/main --oneline

# åˆå¹¶è¿œç¨‹æ›´æ–°ï¼ˆå¦‚æœæœ¬åœ°æœ‰æœªæäº¤çš„æ›´æ”¹ï¼Œå…ˆ stashï¼‰
git pull origin main
```

**å¦‚æœé‡åˆ°å†²çªï¼š**

```bash
# å¦‚æœæœ‰æœ¬åœ°æœªæäº¤çš„æ›´æ”¹ï¼Œå…ˆæš‚å­˜
git stash

# æ‹‰å–æ›´æ–°
git pull origin main

# æ¢å¤æœ¬åœ°æ›´æ”¹ï¼ˆå¦‚æœéœ€è¦ï¼‰
git stash pop
```

### 1.4 éªŒè¯æ›´æ–°æˆåŠŸ

```bash
# æ£€æŸ¥æ–°æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls scripts/eval_baseline.py
ls scripts/hardset_maker.py
ls tests/test_eval_baseline*.py

# æŸ¥çœ‹æ›´æ–°å†…å®¹
git log --oneline -5
```

---

## âœ… æ­¥éª¤ 2ï¼šéªŒè¯ä»£ç æ›´æ–°

### 2.1 æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§

```bash
# æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
test -f scripts/eval_baseline.py && echo "âœ“ eval_baseline.py å­˜åœ¨" || echo "âœ— eval_baseline.py ä¸å­˜åœ¨"
test -f scripts/hardset_maker.py && echo "âœ“ hardset_maker.py å­˜åœ¨" || echo "âœ— hardset_maker.py ä¸å­˜åœ¨"
test -f tests/test_eval_baseline_logic.py && echo "âœ“ æµ‹è¯•æ–‡ä»¶å­˜åœ¨" || echo "âœ— æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨"
```

### 2.2 è¿è¡Œå•å…ƒæµ‹è¯•ï¼ˆå¯é€‰ï¼ŒéªŒè¯ä»£ç é€»è¾‘ï¼‰

```bash
# è¿è¡Œæ ¸å¿ƒé€»è¾‘æµ‹è¯•ï¼ˆä¸ä¾èµ– torchï¼‰
python -m pytest tests/test_eval_baseline_logic.py -v

# å¦‚æœå®‰è£…äº†æ‰€æœ‰ä¾èµ–ï¼Œå¯ä»¥è¿è¡Œå®Œæ•´æµ‹è¯•
python -m pytest tests/test_eval_baseline.py -v
```

---

## ğŸš€ æ­¥éª¤ 3ï¼šå‡†å¤‡ Day3 è¯„ä¼°

### 3.1 æ£€æŸ¥ä¾èµ–æ–‡ä»¶

```bash
# æ£€æŸ¥ baseline æ¨¡å‹æ˜¯å¦å­˜åœ¨
ls -lh checkpoints/baseline-lora/

# åº”è¯¥çœ‹åˆ°ä»¥ä¸‹æ–‡ä»¶ï¼š
# - adapter_model.safetensors (æˆ– adapter_model.bin)
# - adapter_config.json
# - tokenizer.json
# ç­‰

# æ£€æŸ¥æµ‹è¯•æ•°æ®æ˜¯å¦å­˜åœ¨
ls -lh data/test.jsonl

# æ£€æŸ¥å›°éš¾é›†ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
ls -lh data/hard_eval_set.jsonl 2>/dev/null || echo "hard_eval_set.jsonl ä¸å­˜åœ¨ï¼ˆå¯é€‰ï¼‰"
```

### 3.2 æ£€æŸ¥é…ç½®æ–‡ä»¶

```bash
# æŸ¥çœ‹é…ç½®æ–‡ä»¶
cat configs/config.yaml | grep -A 5 "training:"
cat configs/config.yaml | grep -A 5 "model:"
cat configs/config.yaml | grep -A 5 "hardset:"
```

**ç¡®è®¤é…ç½®é¡¹ï¼š**
- `training.output_dir`: åº”è¯¥æŒ‡å‘ `checkpoints/baseline-lora`
- `model.name_or_path`: åŸºç¡€æ¨¡å‹è·¯å¾„ï¼ˆå¦‚ `Qwen/Qwen3-1.7B`ï¼‰
- `hardset.confidence_threshold`: é«˜ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆé»˜è®¤ 0.8ï¼‰

### 3.3 åˆ›å»ºè¾“å‡ºç›®å½•

```bash
# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
mkdir -p output

# æ£€æŸ¥è¾“å‡ºç›®å½•æƒé™
ls -ld output
```

---

## ğŸ“Š æ­¥éª¤ 4ï¼šè¿è¡Œ Day3 è¯„ä¼°

### 4.1 åŸºæœ¬è¯„ä¼°ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰

```bash
# æ¿€æ´»ç¯å¢ƒï¼ˆå¦‚æœè¿˜æ²¡æ¿€æ´»ï¼‰
conda activate emgpkri

# è¿è¡Œè¯„ä¼°
python scripts/eval_baseline.py
```

### 4.2 æŒ‡å®šå‚æ•°è¿è¡Œï¼ˆå¦‚æœéœ€è¦ï¼‰

```bash
# æŒ‡å®š checkpoint è·¯å¾„
python scripts/eval_baseline.py \
    --checkpoint checkpoints/baseline-lora \
    --base-model Qwen/Qwen3-1.7B

# æŒ‡å®šæ•°æ®æ–‡ä»¶
python scripts/eval_baseline.py \
    --test-file test.jsonl \
    --hard-file hard_eval_set.jsonl

# è‡ªå®šä¹‰ç½®ä¿¡åº¦é˜ˆå€¼
python scripts/eval_baseline.py \
    --confidence-threshold 0.9

# æŒ‡å®šè¾“å‡ºç›®å½•
python scripts/eval_baseline.py \
    --output-dir output
```

### 4.3 åå°è¿è¡Œï¼ˆå¦‚æœè¯„ä¼°æ—¶é—´è¾ƒé•¿ï¼‰

```bash
# ä½¿ç”¨ nohup åå°è¿è¡Œ
nohup python scripts/eval_baseline.py > eval_baseline.log 2>&1 &

# æŸ¥çœ‹è¿›ç¨‹
ps aux | grep eval_baseline

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f eval_baseline.log

# æŸ¥çœ‹è¾“å‡ºï¼ˆå®Œæˆåï¼‰
cat eval_baseline.log
```

---

## âœ… æ­¥éª¤ 5ï¼šéªŒè¯è¯„ä¼°ç»“æœ

### 5.1 æ£€æŸ¥è¾“å‡ºæ–‡ä»¶

```bash
# æ£€æŸ¥è¯„ä¼°æŒ‡æ ‡æ–‡ä»¶
ls -lh output/metrics_baseline.json

# æ£€æŸ¥é«˜ç½®ä¿¡é”™è¯¯æ ·æœ¬æ–‡ä»¶
ls -lh output/high_conf_error_samples.jsonl

# æŸ¥çœ‹æ–‡ä»¶å†…å®¹ï¼ˆå‰å‡ è¡Œï¼‰
head -20 output/metrics_baseline.json
head -5 output/high_conf_error_samples.jsonl
```

### 5.2 éªŒè¯è¯„ä¼°æŒ‡æ ‡

```bash
# ä½¿ç”¨ Python æŸ¥çœ‹è¯„ä¼°ç»“æœ
python << EOF
import json

# è¯»å–è¯„ä¼°æŒ‡æ ‡
with open('output/metrics_baseline.json', 'r', encoding='utf-8') as f:
    metrics = json.load(f)

print("=" * 60)
print("æµ‹è¯•é›†è¯„ä¼°ç»“æœ:")
print("=" * 60)
test_metrics = metrics['test_set']
print(f"Accuracy: {test_metrics['accuracy']:.4f}")
print(f"Precision: {test_metrics['precision']:.4f}")
print(f"Recall: {test_metrics['recall']:.4f}")
print(f"F1: {test_metrics['f1']:.4f}")
print(f"æ€»æ ·æœ¬æ•°: {test_metrics['total_samples']}")

if metrics.get('hard_set'):
    print("\n" + "=" * 60)
    print("å›°éš¾é›†è¯„ä¼°ç»“æœ:")
    print("=" * 60)
    hard_metrics = metrics['hard_set']
    print(f"Accuracy: {hard_metrics['accuracy']:.4f}")
    print(f"F1: {hard_metrics['f1']:.4f}")
    print(f"æ€»æ ·æœ¬æ•°: {hard_metrics['total_samples']}")

print("\n" + "=" * 60)
print(f"é«˜ç½®ä¿¡é”™è¯¯æ ·æœ¬æ•°: {metrics['high_conf_error_count']}")
print(f"ç½®ä¿¡åº¦é˜ˆå€¼: {metrics['confidence_threshold']}")
print("=" * 60)
EOF
```

### 5.3 æ£€æŸ¥é«˜ç½®ä¿¡é”™è¯¯æ ·æœ¬

```bash
# ç»Ÿè®¡é«˜ç½®ä¿¡é”™è¯¯æ ·æœ¬æ•°é‡
wc -l output/high_conf_error_samples.jsonl

# æŸ¥çœ‹å‰å‡ ä¸ªé”™è¯¯æ ·æœ¬
head -3 output/high_conf_error_samples.jsonl | python -m json.tool

# åˆ†æé”™è¯¯æ ·æœ¬çš„æ ‡ç­¾åˆ†å¸ƒ
python << EOF
import json

with open('output/high_conf_error_samples.jsonl', 'r', encoding='utf-8') as f:
    samples = [json.loads(line) for line in f]

print(f"æ€»é”™è¯¯æ ·æœ¬æ•°: {len(samples)}")
print(f"å¹³å‡ç½®ä¿¡åº¦: {sum(s['pred_prob'] for s in samples) / len(samples):.4f}")

# ç»Ÿè®¡çœŸå®æ ‡ç­¾åˆ†å¸ƒ
true_label_dist = {}
for s in samples:
    label = s['true_label']
    true_label_dist[label] = true_label_dist.get(label, 0) + 1

print("\nçœŸå®æ ‡ç­¾åˆ†å¸ƒ:")
for label, count in sorted(true_label_dist.items()):
    print(f"  æ ‡ç­¾ {label}: {count} ä¸ª")
EOF
```

---

## ğŸ” æ­¥éª¤ 6ï¼šé—®é¢˜æ’æŸ¥

### 6.1 å¸¸è§é—®é¢˜

**é—®é¢˜ 1ï¼šæ¨¡å‹åŠ è½½å¤±è´¥**

```bash
# æ£€æŸ¥ checkpoint è·¯å¾„æ˜¯å¦æ­£ç¡®
ls -la checkpoints/baseline-lora/

# æ£€æŸ¥åŸºç¡€æ¨¡å‹è·¯å¾„
# å¦‚æœæ˜¯æœ¬åœ°æ¨¡å‹ï¼Œç¡®è®¤è·¯å¾„å­˜åœ¨
# å¦‚æœæ˜¯ HuggingFace æ¨¡å‹ï¼Œç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸
```

**é—®é¢˜ 2ï¼šCUDA å†…å­˜ä¸è¶³**

```bash
# å‡å° batch_size
python scripts/eval_baseline.py --batch-size 8

# æˆ–ä½¿ç”¨ CPUï¼ˆè¾ƒæ…¢ï¼‰
python scripts/eval_baseline.py --device cpu
```

**é—®é¢˜ 3ï¼šæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨**

```bash
# æ£€æŸ¥æ•°æ®æ–‡ä»¶
ls -lh data/test.jsonl
ls -lh data/hard_eval_set.jsonl

# å¦‚æœ hard_eval_set.jsonl ä¸å­˜åœ¨ï¼Œå¯ä»¥å…ˆè¿è¡Œ hardset_maker.py
python scripts/hardset_maker.py
```

**é—®é¢˜ 4ï¼šé…ç½®æ–‡ä»¶é”™è¯¯**

```bash
# éªŒè¯é…ç½®æ–‡ä»¶æ ¼å¼
python -c "import yaml; yaml.safe_load(open('configs/config.yaml'))"
```

### 6.2 è°ƒè¯•æ¨¡å¼

```bash
# ä½¿ç”¨ Python äº¤äº’å¼è°ƒè¯•
python << EOF
import sys
sys.path.insert(0, 'scripts')
from eval_baseline import load_config, load_baseline_model

# æµ‹è¯•é…ç½®åŠ è½½
config = load_config()
print("é…ç½®åŠ è½½æˆåŠŸ")
print(f"æ•°æ®ç›®å½•: {config.get('data_dir')}")
print(f"è¾“å‡ºç›®å½•: {config.get('output_dir')}")

# æµ‹è¯•æ¨¡å‹åŠ è½½ï¼ˆå¦‚æœ GPU å¯ç”¨ï¼‰
# model, tokenizer = load_baseline_model(
#     'checkpoints/baseline-lora',
#     'Qwen/Qwen3-1.7B'
# )
# print("æ¨¡å‹åŠ è½½æˆåŠŸ")
EOF
```

---

## ğŸ“ æ­¥éª¤ 7ï¼šç»“æœè®°å½•

### 7.1 ä¿å­˜è¯„ä¼°ç»“æœ

```bash
# å¤‡ä»½è¯„ä¼°ç»“æœ
mkdir -p results/day3
cp output/metrics_baseline.json results/day3/
cp output/high_conf_error_samples.jsonl results/day3/

# è®°å½•è¯„ä¼°æ—¶é—´
echo "$(date): Day3 è¯„ä¼°å®Œæˆ" >> results/day3/evaluation_log.txt
```

### 7.2 ç”Ÿæˆç®€è¦æŠ¥å‘Š

```bash
python << EOF
import json
from datetime import datetime

with open('output/metrics_baseline.json', 'r', encoding='utf-8') as f:
    metrics = json.load(f)

report = f"""
Day3 åŸºçº¿è¯„ä¼°æŠ¥å‘Š
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

æµ‹è¯•é›†ç»“æœ:
- Accuracy: {metrics['test_set']['accuracy']:.4f}
- F1: {metrics['test_set']['f1']:.4f}
- Precision: {metrics['test_set']['precision']:.4f}
- Recall: {metrics['test_set']['recall']:.4f}
- æ ·æœ¬æ•°: {metrics['test_set']['total_samples']}
"""

if metrics.get('hard_set'):
    report += f"""
å›°éš¾é›†ç»“æœ:
- Accuracy: {metrics['hard_set']['accuracy']:.4f}
- F1: {metrics['hard_set']['f1']:.4f}
- æ ·æœ¬æ•°: {metrics['hard_set']['total_samples']}
"""

report += f"""
é«˜ç½®ä¿¡é”™è¯¯æ ·æœ¬:
- æ•°é‡: {metrics['high_conf_error_count']}
- é˜ˆå€¼: {metrics['confidence_threshold']}
"""

print(report)
with open('results/day3/report.txt', 'w', encoding='utf-8') as f:
    f.write(report)
EOF

cat results/day3/report.txt
```

---

## ğŸ¯ å®Œæˆæ£€æŸ¥æ¸…å•

- [ ] âœ… ä» git æˆåŠŸæ‹‰å–æœ€æ–°ä»£ç 
- [ ] âœ… éªŒè¯æ–°æ–‡ä»¶å­˜åœ¨
- [ ] âœ… æ£€æŸ¥ baseline æ¨¡å‹å­˜åœ¨
- [ ] âœ… æ£€æŸ¥æµ‹è¯•æ•°æ®å­˜åœ¨
- [ ] âœ… è¿è¡Œ eval_baseline.py
- [ ] âœ… éªŒè¯è¾“å‡ºæ–‡ä»¶ç”Ÿæˆ
- [ ] âœ… æ£€æŸ¥è¯„ä¼°æŒ‡æ ‡åˆç†
- [ ] âœ… æ£€æŸ¥é«˜ç½®ä¿¡é”™è¯¯æ ·æœ¬
- [ ] âœ… ä¿å­˜è¯„ä¼°ç»“æœ

---

## ğŸ“š ä¸‹ä¸€æ­¥

å®Œæˆ Day3 è¯„ä¼°åï¼Œå¯ä»¥ï¼š

1. **åˆ†æè¯„ä¼°ç»“æœ**ï¼šæŸ¥çœ‹ baseline åœ¨æµ‹è¯•é›†å’Œå›°éš¾é›†ä¸Šçš„è¡¨ç°å·®å¼‚
2. **åˆ†æé«˜ç½®ä¿¡é”™è¯¯**ï¼šç ”ç©¶ä¸ºä»€ä¹ˆæ¨¡å‹å¯¹è¿™äº›æ ·æœ¬é«˜ç½®ä¿¡ä½†é¢„æµ‹é”™è¯¯
3. **å‡†å¤‡ Day4**ï¼šå¼€å§‹ä¸ç¡®å®šæ€§åˆ†æï¼ˆuncertainty_analysis.pyï¼‰

---

## ğŸ’¡ æç¤º

- å¦‚æœè¯„ä¼°æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä½¿ç”¨ `screen` æˆ– `tmux` ä¿æŒä¼šè¯
- å®šæœŸæ£€æŸ¥ç£ç›˜ç©ºé—´ï¼š`df -h`
- å¦‚æœé‡åˆ°é—®é¢˜ï¼ŒæŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ï¼š`tail -f eval_baseline.log`
- å¯ä»¥å¹¶è¡Œè¿è¡Œå¤šä¸ªè¯„ä¼°ä»»åŠ¡ï¼ˆä½¿ç”¨ä¸åŒçš„è¾“å‡ºç›®å½•ï¼‰

---

**æœ€åæ›´æ–°**ï¼š2025-12-12  
**é€‚ç”¨ç‰ˆæœ¬**ï¼šDay3 è¯„ä¼°è„šæœ¬

