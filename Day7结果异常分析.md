# Day7结果异常分析

**日期**：2025-12-15  
**问题**：词表优化后Day7的α*搜索结果与理论预期相反

---

## 📊 结果对比

### 理论预期

EMG核心假设：**低不确定性(u)时信任模型，高不确定性(u)时信任知识**

- **低u（u < 0.1）**：α应该大（接近1.0，信任模型）
- **高u（u > 0.3）**：α应该小（接近0.0，信任知识）

### 优化前（旧结果，符合理论）

| Bucket | u_mean | n_samples | alpha_star | 说明 |
|--------|--------|-----------|------------|------|
| 0 | 0.016 | 3,912 | **0.75** | ✅ 低u，信任模型 |
| 1 | 0.146 | 368 | **0.25** | ✅ 中等u，平衡 |
| 2 | 0.248 | 284 | **0.50** | ✅ 中等u，平衡 |
| 3 | 0.349 | 207 | **0.00** | ✅ 高u，信任知识 |
| 4 | 0.451 | 177 | **0.00** | ✅ 高u，信任知识 |

### 优化后（新结果，**与理论相反**）

| Bucket | u_mean | n_samples | alpha_star | 说明 |
|--------|--------|-----------|------------|------|
| 0 | 0.016 | 3,912 | **0.50** ⚠️ | ❌ 低u但α不够大（应该>0.75） |
| 1 | 0.146 | 368 | **0.75** | ⚠️ 中等u但α变大 |
| 2 | 0.248 | 284 | **0.75** | ⚠️ 中等u但α变大 |
| 3 | 0.349 | 207 | **1.00** ❌ | ❌ 高u但完全信任模型（应该<0.5） |
| 4 | 0.451 | 177 | **1.00** ❌ | ❌ 高u但完全信任模型（应该<0.5） |

---

## 🔍 问题诊断

### 核心发现

1. **低u时α变小**：Bucket 0的α*从0.75降到0.50
   - 说明：q0质量可能变好了，所以低u时也需要更多使用q0？

2. **高u时α变大**：Bucket 3和4的α*从0.00升到1.00
   - 说明：**q0质量显著下降**，在高u情况下完全不可信，只能完全信任模型

### 可能原因分析

#### 原因1：词表优化过度，误删有用词（**最可能**）

**假设**：词表从36,012减少到5,875（-83.7%），可能误删了一些有用的敏感词

**证据**：
- 高u样本（模型不确定）通常需要知识帮助
- 如果q0匹配不到相关词（因为词被删了），q0就变成噪声
- 结果：高u时使用q0反而降低性能，只能完全信任模型（α=1.0）

**验证方法**：
```bash
# 对比优化前后的q0质量
python scripts/eval_q0.py --q0-file data/q0_dev.jsonl --baseline-file output/dev_with_uncertainty.jsonl
```

#### 原因2：q0参数未调整，不匹配新的词表规模

**假设**：词表规模大幅减少后，需要重新调整q0参数

**当前q0参数**（可能不适用优化后的词表）：
- `max_sensitive_prob`: 0.75
- `min_matches_for_sensitive`: 2
- `politics_weight`: 0.6
- `abuse_weight`: 0.5

**验证方法**：检查q0的匹配率和概率分布

#### 原因3：词表优化后，匹配精度提升但召回率下降

**假设**：
- 精度提升：保留的词都是高质量词，匹配更准确
- 召回率下降：很多有用词被删，导致漏检

**影响**：
- 低u样本：模型本身就很确定，q0只是补充，影响不大
- 高u样本：模型不确定，依赖q0，但q0漏检导致无法提供有效帮助

---

## 🔬 诊断步骤

### 步骤1：评估优化前后q0质量对比

```bash
# 如果还有旧的q0_dev.jsonl备份，可以对比
# 新q0质量评估
python scripts/eval_q0.py \
    --q0-file data/q0_dev.jsonl \
    --baseline-file output/dev_with_uncertainty.jsonl \
    --output-dir output
```

**检查指标**：
- q0准确率（应该>65%）
- q0召回率（是否大幅下降？）
- q0 F1分数
- q0概率分布（max(q0)的分布）

### 步骤2：分析q0在不同u bucket中的表现

**检查**：高u bucket中q0的准确率是否显著低于低u bucket

### 步骤3：分析词表匹配统计

**检查**：
- 优化后词表匹配率是否下降？
- 高u样本中q0匹配到的词数是否减少？

---

## 💡 解决方案

### 方案1：调整q0参数（快速尝试）

如果q0质量只是略微下降，可以尝试调整参数：

```yaml
# configs/config.yaml
q0:
  max_sensitive_prob: 0.65  # 从0.75降低
  min_matches_for_sensitive: 1  # 从2降低（词表小了，降低匹配要求）
  politics_weight: 0.7  # 从0.6提高
  abuse_weight: 0.6  # 从0.5提高
```

**重新运行Day6和Day7验证效果**

### 方案2：恢复部分被删的词（如果确认误删）

如果诊断确认是词表过度删除导致，可以：
1. 分析被删的词中是否有高频匹配词
2. 恢复部分有用的词
3. 重新优化词表（更保守的策略）

### 方案3：接受现状，使用门控机制缓解

如果q0质量下降是词表优化的必然代价，可以使用门控机制：

- **知识阈值门控**：当`max(q0) < threshold`时，α=1.0（完全信任模型）
- **一致性门控**：当`argmax(p) != argmax(q0)`时，α=1.0

**注意**：这个方案相当于在高u时默认信任模型，与EMG的理论假设冲突

---

## 🎯 建议

1. **立即诊断**：先运行`eval_q0.py`评估q0质量
2. **对比分析**：如果有旧q0备份，对比优化前后的q0准确率
3. **针对性修复**：
   - 如果q0质量下降明显 → 考虑恢复部分词或调整参数
   - 如果q0质量保持 → 可能需要重新理解EMG在这个数据集上的表现

---

## 📝 下一步

1. ✅ 运行`eval_q0.py`评估当前q0质量
2. ⏳ 分析q0在不同u bucket中的表现差异
3. ⏳ 根据诊断结果决定修复方案

